{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Agent Bot Development & Testing Notebook\n",
    "\n",
    "This comprehensive notebook tests all classes, functions, and logic step by step:\n",
    "\n",
    "1. **Configuration Testing** - Verify environment setup\n",
    "2. **Gemini Client Testing** - Test AI model connectivity\n",
    "3. **Google Scholar API Testing** - Test paper search functionality\n",
    "4. **Document Processing Testing** - Test PDF/HTML processing\n",
    "5. **Vector Store Testing** - Test embeddings and similarity search\n",
    "6. **Research Agent Integration** - Test full workflow\n",
    "7. **Error Handling Testing** - Test edge cases and failures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.12.10 (tags/v3.12.10:0cc8128, Apr  8 2025, 12:21:36) [MSC v.1943 64 bit (AMD64)]\n",
      "Current working directory: e:\\Research_Agent_Bot\n",
      "Test started at: 2025-07-24 08:48:57.507358\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Import all necessary libraries\n",
    "import os\n",
    "import sys\n",
    "import asyncio\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "print(f\"Test started at: {datetime.now()}\")\n",
    "print(\"\" + \"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuration loaded successfully\n",
      "   - Gemini Model: gemini-2.5-flash\n",
      "   - Max Results: 10\n",
      "   - Temperature: 0.3\n",
      "   - Vector DB Path: ./chroma_db\n",
      "   - Cache Dir: ./cache\n",
      "   - Gemini API Key: ‚úÖ Present\n",
      "   - SerpAPI Key: ‚úÖ Present\n"
     ]
    }
   ],
   "source": [
    "# Test configuration loading\n",
    "try:\n",
    "    from config import config\n",
    "    print(\"‚úÖ Configuration loaded successfully\")\n",
    "    print(f\"   - Gemini Model: {config.GEMINI_MODEL}\")\n",
    "    print(f\"   - Max Results: {config.MAX_RESULTS}\")\n",
    "    print(f\"   - Temperature: {config.TEMPERATURE}\")\n",
    "    print(f\"   - Vector DB Path: {config.VECTOR_DB_PATH}\")\n",
    "    print(f\"   - Cache Dir: {config.CACHE_DIR}\")\n",
    "    \n",
    "    # Check API keys (without revealing them)\n",
    "    print(f\"   - Gemini API Key: {'‚úÖ Present' if config.GEMINI_API_KEY else '‚ùå Missing'}\")\n",
    "    print(f\"   - SerpAPI Key: {'‚úÖ Present' if config.SERPAPI_KEY else '‚ùå Missing'}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Configuration failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Gemini Client Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Research_Agent_Bot\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-07-24 08:49:07,411 - gemini_client - INFO - Initialized Gemini model: gemini-2.5-flash\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing Gemini Client...\n",
      "‚úÖ Gemini client initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-24 08:49:08,840 - gemini_client - INFO - Gemini API connection test successful\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   - Connection test: ‚úÖ Passed\n",
      "   - Model info: {\n",
      "  \"name\": \"models/gemini-2.5-flash\",\n",
      "  \"display_name\": \"Gemini 2.5 Flash\",\n",
      "  \"description\": \"Stable version of Gemini 2.5 Flash, our mid-size multimodal model that supports up to 1 million tokens, released in June of 2025.\",\n",
      "  \"supported_generation_methods\": [\n",
      "    \"generateContent\",\n",
      "    \"countTokens\",\n",
      "    \"createCachedContent\",\n",
      "    \"batchGenerateContent\"\n",
      "  ]\n",
      "}\n",
      "   - Test response: Test successful...\n"
     ]
    }
   ],
   "source": [
    "# Test Gemini Client initialization and basic functionality\n",
    "try:\n",
    "    from gemini_client import GeminiClient\n",
    "    \n",
    "    print(\"üß™ Testing Gemini Client...\")\n",
    "    \n",
    "    # Initialize client\n",
    "    gemini_client = GeminiClient(\n",
    "        api_key=config.GEMINI_API_KEY,\n",
    "        model=config.GEMINI_MODEL,\n",
    "        temperature=config.TEMPERATURE\n",
    "    )\n",
    "    print(\"‚úÖ Gemini client initialized\")\n",
    "    \n",
    "    # Test connection\n",
    "    connection_test = gemini_client.test_connection()\n",
    "    print(f\"   - Connection test: {'‚úÖ Passed' if connection_test else '‚ùå Failed'}\")\n",
    "    \n",
    "    # Get model info\n",
    "    model_info = gemini_client.get_model_info()\n",
    "    print(f\"   - Model info: {json.dumps(model_info, indent=2)}\")\n",
    "    \n",
    "    # Test simple invocation\n",
    "    test_message = \"Hello, this is a test message. Please respond with 'Test successful'\"\n",
    "    response = gemini_client.invoke([test_message])\n",
    "    print(f\"   - Test response: {response.content[:100]}...\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Gemini Client test failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Google Scholar API Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing Google Scholar API...\n",
      "‚úÖ Scholar API initialized\n",
      "   - Original query: machine learning algorithms\n",
      "   - Refined query: machine learning algorithms\n",
      "   - Found 3 papers\n",
      "   - First paper: A review of supervised machine learning algorithms...\n",
      "‚ùå Scholar API test failed: sequence item 0: expected str instance, dict found\n"
     ]
    }
   ],
   "source": [
    "# Test Google Scholar API functionality\n",
    "try:\n",
    "    from scholar_api import GoogleScholarAPI, ScholarResult\n",
    "    \n",
    "    print(\"üß™ Testing Google Scholar API...\")\n",
    "    \n",
    "    # Initialize API\n",
    "    scholar_api = GoogleScholarAPI(config.SERPAPI_KEY)\n",
    "    print(\"‚úÖ Scholar API initialized\")\n",
    "    \n",
    "    # Test query refinement\n",
    "    test_query = \"machine learning algorithms\"\n",
    "    refined_query = scholar_api.refine_query(test_query)\n",
    "    print(f\"   - Original query: {test_query}\")\n",
    "    print(f\"   - Refined query: {refined_query}\")\n",
    "    \n",
    "    # Test paper search (async)\n",
    "    async def test_scholar_search():\n",
    "        results = await scholar_api.search_papers(refined_query, max_results=3)\n",
    "        return results\n",
    "    \n",
    "    search_results = await test_scholar_search()\n",
    "    print(f\"   - Found {len(search_results)} papers\")\n",
    "    \n",
    "    # Display first result details\n",
    "    if search_results:\n",
    "        first_paper = search_results[0]\n",
    "        print(f\"   - First paper: {first_paper.title[:80]}...\")\n",
    "        print(f\"   - Authors: {', '.join(first_paper.authors[:3]) if first_paper.authors else 'Unknown'}\")\n",
    "        print(f\"   - Year: {first_paper.year or 'Unknown'}\")\n",
    "        print(f\"   - Citations: {first_paper.citation_count}\")\n",
    "        print(f\"   - PDF URL: {'‚úÖ Available' if first_paper.pdf_url else '‚ùå Not available'}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Scholar API test failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Document Processing Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing Document Processor...\n",
      "‚úÖ Document processor initialized\n",
      "   - Cache directory: ./cache\n",
      "   - Testing with paper: Types of machine learning algorithms...\n",
      "   - Extracted 170 chunks\n",
      "   - First chunk preview: Types of Machine Learning Algorithms 19 Types of Machine Learning Algorithms Taiwo Oladipupo Ayodele...\n",
      "   - Chunk metadata: {'title': 'Types of machine learning algorithms', 'page': 1, 'chunk_id': 'page_1_chunk_0', 'total_pages': 32}\n"
     ]
    }
   ],
   "source": [
    "# Test Document Processor functionality\n",
    "try:\n",
    "    from document_processor import DocumentProcessor, DocumentChunk\n",
    "    \n",
    "    print(\"üß™ Testing Document Processor...\")\n",
    "    \n",
    "    # Initialize processor\n",
    "    doc_processor = DocumentProcessor(config.CACHE_DIR)\n",
    "    print(\"‚úÖ Document processor initialized\")\n",
    "    print(f\"   - Cache directory: {config.CACHE_DIR}\")\n",
    "    \n",
    "    # Test with a paper that has PDF (if available from search results)\n",
    "    if 'search_results' in locals() and search_results:\n",
    "        paper_with_pdf = None\n",
    "        for paper in search_results:\n",
    "            if paper.pdf_url:\n",
    "                paper_with_pdf = paper\n",
    "                break\n",
    "        \n",
    "        if paper_with_pdf:\n",
    "            print(f\"   - Testing with paper: {paper_with_pdf.title[:50]}...\")\n",
    "            \n",
    "            # Process the paper (async)\n",
    "            async def test_document_processing():\n",
    "                chunks = await doc_processor.process_paper(\n",
    "                    paper_with_pdf.pdf_url, \n",
    "                    paper_with_pdf.title\n",
    "                )\n",
    "                return chunks\n",
    "            \n",
    "            document_chunks = await test_document_processing()\n",
    "            print(f\"   - Extracted {len(document_chunks)} chunks\")\n",
    "            \n",
    "            if document_chunks:\n",
    "                first_chunk = document_chunks[0]\n",
    "                print(f\"   - First chunk preview: {first_chunk.text[:100]}...\")\n",
    "                print(f\"   - Chunk metadata: {first_chunk.metadata}\")\n",
    "        else:\n",
    "            print(\"   - No papers with PDF URLs found for testing\")\n",
    "    else:\n",
    "        print(\"   - No search results available for document processing test\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Document processor test failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Vector Store Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing Vector Store...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-24 08:50:25,684 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu\n",
      "2025-07-24 08:50:25,685 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n",
      "2025-07-24 08:50:38,203 - vector_store - INFO - Initialized vector store with 11290 documents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Vector store initialized\n",
      "   - Current stats: {'total_chunks': 11290, 'unique_papers': 17, 'papers': ['Exploring large language model based intelligent agents: Definitions, methods, and prospects', 'Logic-based technologies for multi-agent systems: a systematic literature review', 'Exploring autonomous agents through the lens of large language models: A review', 'AI and Agents: State of the Art', 'Longheads: Multi-head attention is secretly a long context processor', 'Exploring self-attention mechanisms for speech separation', 'EEG-transformer: Self-attention from transformer architecture for decoding EEG of imagined speech', 'Architectures and applications of intelligent agents: A survey', 'Agents: An open-source framework for autonomous language agents', 'Multi-modal and multi-agent systems meet rationality: A survey', 'Moh: Multi-head attention as mixture-of-head attention', \"Machine learning-based virtual screening and its applications to Alzheimer's drug discovery: a review\", 'Unveiling and harnessing hidden attention sinks: Enhancing large language models without training through attention calibration', 'Analyzing multi-head self-attention: Specialized heads do the heavy lifting, the rest can be pruned', 'LLM-Based Multi-Agent Systems for Software Engineering: Literature Review, Vision, and the Road Ahead', 'An artificial intelligence accelerated virtual screening platform for drug discovery', 'A survey on context-aware multi-agent systems: techniques, challenges and future directions']}\n",
      "   - Adding 170 chunks to vector store...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:08<00:00,  1.39s/it]\n",
      "2025-07-24 08:50:48,869 - vector_store - INFO - Added 170 document chunks to vector store\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   - Add documents: ‚úÖ Success\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 31.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   - Similarity search results: 3 found\n",
      "     Result 1: Score=0.634, Text=Types of Machine Learning Algorithms 19 Types of Machine Learning Algorithms Tai...\n",
      "     Result 2: Score=0.581, Text=Otherwise, it wouldnt be easy for whoever requires that input to figure out what...\n",
      "     Result 3: Score=0.569, Text=Types of Machine Learning Algorithms 25 Unsupervised learning has produced many ...\n",
      "   - Updated stats: {'total_chunks': 11460, 'unique_papers': 18, 'papers': ['Exploring large language model based intelligent agents: Definitions, methods, and prospects', 'Logic-based technologies for multi-agent systems: a systematic literature review', 'Exploring autonomous agents through the lens of large language models: A review', 'AI and Agents: State of the Art', 'Longheads: Multi-head attention is secretly a long context processor', 'Exploring self-attention mechanisms for speech separation', 'EEG-transformer: Self-attention from transformer architecture for decoding EEG of imagined speech', 'Types of machine learning algorithms', 'Architectures and applications of intelligent agents: A survey', 'Agents: An open-source framework for autonomous language agents', 'Multi-modal and multi-agent systems meet rationality: A survey', 'Moh: Multi-head attention as mixture-of-head attention', \"Machine learning-based virtual screening and its applications to Alzheimer's drug discovery: a review\", 'Unveiling and harnessing hidden attention sinks: Enhancing large language models without training through attention calibration', 'Analyzing multi-head self-attention: Specialized heads do the heavy lifting, the rest can be pruned', 'LLM-Based Multi-Agent Systems for Software Engineering: Literature Review, Vision, and the Road Ahead', 'An artificial intelligence accelerated virtual screening platform for drug discovery', 'A survey on context-aware multi-agent systems: techniques, challenges and future directions']}\n"
     ]
    }
   ],
   "source": [
    "# Test Vector Store functionality\n",
    "try:\n",
    "    from vector_store import VectorStore\n",
    "    \n",
    "    print(\"üß™ Testing Vector Store...\")\n",
    "    \n",
    "    # Initialize vector store\n",
    "    vector_store = VectorStore(config.VECTOR_DB_PATH, config.EMBEDDING_MODEL)\n",
    "    print(\"‚úÖ Vector store initialized\")\n",
    "    \n",
    "    # Get current stats\n",
    "    stats = vector_store.get_collection_stats()\n",
    "    print(f\"   - Current stats: {stats}\")\n",
    "    \n",
    "    # Test adding documents (if we have chunks from previous step)\n",
    "    if 'document_chunks' in locals() and document_chunks:\n",
    "        print(f\"   - Adding {len(document_chunks)} chunks to vector store...\")\n",
    "        success = vector_store.add_documents(document_chunks)\n",
    "        print(f\"   - Add documents: {'‚úÖ Success' if success else '‚ùå Failed'}\")\n",
    "        \n",
    "        # Test similarity search\n",
    "        test_search_query = \"machine learning algorithms\"\n",
    "        search_results_vector = vector_store.similarity_search(test_search_query, k=3)\n",
    "        print(f\"   - Similarity search results: {len(search_results_vector)} found\")\n",
    "        \n",
    "        if search_results_vector:\n",
    "            for i, (text, metadata, score) in enumerate(search_results_vector):\n",
    "                print(f\"     Result {i+1}: Score={score:.3f}, Text={text[:80]}...\")\n",
    "    else:\n",
    "        print(\"   - No document chunks available for testing\")\n",
    "        \n",
    "        # Test with sample data\n",
    "        sample_chunks = [\n",
    "            DocumentChunk(\n",
    "                text=\"Machine learning is a subset of artificial intelligence that focuses on algorithms.\",\n",
    "                metadata={\"title\": \"Sample Paper 1\", \"page\": 1},\n",
    "                source=\"test\",\n",
    "                page_number=1\n",
    "            ),\n",
    "            DocumentChunk(\n",
    "                text=\"Deep learning uses neural networks with multiple layers to process data.\",\n",
    "                metadata={\"title\": \"Sample Paper 2\", \"page\": 1},\n",
    "                source=\"test\",\n",
    "                page_number=1\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        success = vector_store.add_documents(sample_chunks)\n",
    "        print(f\"   - Add sample documents: {'‚úÖ Success' if success else '‚ùå Failed'}\")\n",
    "        \n",
    "        # Test search with sample data\n",
    "        search_results_vector = vector_store.similarity_search(\"neural networks\", k=2)\n",
    "        print(f\"   - Sample search results: {len(search_results_vector)} found\")\n",
    "    \n",
    "    # Updated stats\n",
    "    updated_stats = vector_store.get_collection_stats()\n",
    "    print(f\"   - Updated stats: {updated_stats}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Vector store test failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Research Agent Integration Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-24 08:50:50,953 - gemini_client - INFO - Initialized Gemini model: gemini-2.5-flash\n",
      "2025-07-24 08:50:50,995 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu\n",
      "2025-07-24 08:50:50,995 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing Research Agent Integration...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-24 08:50:54,718 - vector_store - INFO - Initialized vector store with 11460 documents\n",
      "2025-07-24 08:50:56,809 - gemini_client - INFO - Gemini API connection test successful\n",
      "2025-07-24 08:50:57,201 - research_agent - INFO - Connected to Gemini model: Gemini 2.5 Flash\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Research agent initialized\n",
      "   - Test query: What are the latest developments in transformer architectures?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-24 08:51:02,857 - research_agent - INFO - Refining query: What are the latest developments in transformer architectures?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   - Refined query: (\"transformer architectures\" OR \"attention mechanisms\") AND (\"recent advances\" OR \"novel\" OR \"state-of-the-art\" OR \"efficient\" OR \"scalable\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-24 08:51:07,304 - research_agent - INFO - Refined query: (\"transformer architectures\" OR \"attention mechanisms\" OR \"large language models\" OR \"vision transformers\" OR \"multimodal transformers\") AND (\"recent advancements\" OR \"novel architectures\" OR \"state-of-the-art\" OR \"survey\" OR \"review\")\n",
      "2025-07-24 08:51:07,305 - research_agent - INFO - Searching papers for: (\"transformer architectures\" OR \"attention mechanisms\" OR \"large language models\" OR \"vision transformers\" OR \"multimodal transformers\") AND (\"recent advancements\" OR \"novel architectures\" OR \"state-of-the-art\" OR \"survey\" OR \"review\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   - Step 1 (Refine Query): query_refined\n",
      "     Refined: (\"transformer architectures\" OR \"attention mechanisms\" OR \"large language models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-24 08:51:07,988 - research_agent - INFO - Found 10 papers\n",
      "2025-07-24 08:51:07,990 - research_agent - INFO - Processing documents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   - Step 2 (Search Papers): papers_found\n",
      "     Found 10 papers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-24 08:51:14,509 - bs4.dammit - WARNING - Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 98/98 [02:05<00:00,  1.28s/it]\n",
      "2025-07-24 08:53:31,337 - vector_store - INFO - Added 3110 document chunks to vector store\n",
      "2025-07-24 08:53:31,349 - research_agent - INFO - Processed paper: Transformers in vision: A survey\n",
      "2025-07-24 08:53:31,351 - research_agent - INFO - Extracting context\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   - Step 3 (Process Documents): documents_processed\n",
      "     Processed 1 papers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 27.79it/s]\n",
      "2025-07-24 08:53:32,025 - research_agent - INFO - Extracted 10 relevant chunks\n",
      "2025-07-24 08:53:32,026 - research_agent - INFO - Generating answer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   - Step 4 (Extract Context): context_extracted\n",
      "     Context chunks: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-24 08:53:44,411 - research_agent - INFO - Answer generated successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   - Step 5 (Generate Answer): answer_generated\n",
      "     Answer preview: I apologize, but the provided context from the research papers is heavily corrupted and unreadable. ...\n"
     ]
    }
   ],
   "source": [
    "# Test full Research Agent integration\n",
    "try:\n",
    "    from research_agent import ResearchAgent, ResearchState\n",
    "    \n",
    "    print(\"üß™ Testing Research Agent Integration...\")\n",
    "    \n",
    "    # Initialize research agent\n",
    "    research_agent = ResearchAgent()\n",
    "    print(\"‚úÖ Research agent initialized\")\n",
    "    \n",
    "    # Test individual components\n",
    "    test_query = \"What are the latest developments in transformer architectures?\"\n",
    "    print(f\"   - Test query: {test_query}\")\n",
    "    \n",
    "    # Test query refinement\n",
    "    refined_query = research_agent.query_refinement_tool.refine_query(test_query)\n",
    "    print(f\"   - Refined query: {refined_query}\")\n",
    "    \n",
    "    # Test each step of the workflow\n",
    "    initial_state = {\n",
    "        'original_query': test_query,\n",
    "        'refined_query': '',\n",
    "        'search_results': [],\n",
    "        'processed_documents': [],\n",
    "        'context_chunks': [],\n",
    "        'final_answer': '',\n",
    "        'error': None,\n",
    "        'step': 'initialized'\n",
    "    }\n",
    "    \n",
    "    # Step 1: Query refinement\n",
    "    state = await research_agent._refine_query(initial_state)\n",
    "    print(f\"   - Step 1 (Refine Query): {state['step']}\")\n",
    "    print(f\"     Refined: {state.get('refined_query', 'N/A')[:80]}...\")\n",
    "    \n",
    "    # Step 2: Search papers\n",
    "    if not state.get('error'):\n",
    "        state = await research_agent._search_papers(state)\n",
    "        print(f\"   - Step 2 (Search Papers): {state['step']}\")\n",
    "        print(f\"     Found {len(state.get('search_results', []))} papers\")\n",
    "    \n",
    "    # Step 3: Process documents (limited for testing)\n",
    "    if not state.get('error') and state.get('search_results'):\n",
    "        # Limit to first paper for testing\n",
    "        state['search_results'] = state['search_results'][:1]\n",
    "        state = await research_agent._process_documents(state)\n",
    "        print(f\"   - Step 3 (Process Documents): {state['step']}\")\n",
    "        print(f\"     Processed {len(state.get('processed_documents', []))} papers\")\n",
    "    \n",
    "    # Step 4: Extract context\n",
    "    if not state.get('error'):\n",
    "        state = await research_agent._extract_context(state)\n",
    "        print(f\"   - Step 4 (Extract Context): {state['step']}\")\n",
    "        print(f\"     Context chunks: {len(state.get('context_chunks', []))}\")\n",
    "    \n",
    "    # Step 5: Generate answer\n",
    "    if not state.get('error'):\n",
    "        state = await research_agent._generate_answer(state)\n",
    "        print(f\"   - Step 5 (Generate Answer): {state['step']}\")\n",
    "        print(f\"     Answer preview: {state.get('final_answer', 'N/A')[:100]}...\")\n",
    "    \n",
    "    # Print any errors\n",
    "    if state.get('error'):\n",
    "        print(f\"   - ‚ùå Error occurred: {state['error']}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Research agent integration test failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Full Workflow Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-24 08:53:44,533 - research_agent - INFO - Refining query: machine learning applications\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing Complete Research Workflow...\n",
      "   - Running complete workflow for: machine learning applications\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-24 08:53:51,946 - research_agent - INFO - Refined query: \"machine learning\" AND (\"applications\" OR \"use cases\" OR \"case studies\" OR \"real-world implementation\" OR \"industry solutions\")\n",
      "2025-07-24 08:53:51,948 - research_agent - INFO - Searching papers for: \"machine learning\" AND (\"applications\" OR \"use cases\" OR \"case studies\" OR \"real-world implementation\" OR \"industry solutions\")\n",
      "2025-07-24 08:53:53,262 - research_agent - INFO - Found 10 papers\n",
      "2025-07-24 08:53:53,264 - research_agent - INFO - Processing documents\n",
      "2025-07-24 08:53:53,915 - document_processor - WARNING - Failed to download https://dl.acm.org/doi/pdf/10.1145/3533378: 403\n",
      "2025-07-24 08:53:57,081 - document_processor - ERROR - Error processing PDF: EOF marker not found\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.34it/s]\n",
      "2025-07-24 08:54:02,673 - vector_store - INFO - Added 40 document chunks to vector store\n",
      "2025-07-24 08:54:02,674 - research_agent - INFO - Processed paper: An Introduction to Optimization: With Applications to Machine Learning\n",
      "2025-07-24 08:54:02,732 - document_processor - WARNING - Failed to download https://dl.acm.org/doi/pdf/10.1145/219717.219768: 403\n",
      "2025-07-24 08:54:04,532 - bs4.dammit - WARNING - Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:13<00:00,  1.22s/it]\n",
      "2025-07-24 08:54:19,817 - vector_store - INFO - Added 325 document chunks to vector store\n",
      "2025-07-24 08:54:19,819 - research_agent - INFO - Processed paper: Machine learning and its applications to biology\n",
      "2025-07-24 08:54:19,906 - document_processor - WARNING - Failed to download https://onlinelibrary.wiley.com/doi/pdf/10.1155/2022/1833507: 403\n",
      "2025-07-24 08:54:19,909 - research_agent - INFO - Extracting context\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 22.73it/s]\n",
      "2025-07-24 08:54:20,571 - research_agent - INFO - Extracted 10 relevant chunks\n",
      "2025-07-24 08:54:20,572 - research_agent - INFO - Generating answer\n",
      "2025-07-24 08:54:26,965 - research_agent - INFO - Answer generated successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   - ‚úÖ Workflow completed successfully\n",
      "   - Final answer: No answer...\n"
     ]
    }
   ],
   "source": [
    "# Test the complete research workflow using the graph\n",
    "try:\n",
    "    print(\"üß™ Testing Complete Research Workflow...\")\n",
    "    \n",
    "    # Use the compiled graph for end-to-end testing\n",
    "    if 'research_agent' in locals():\n",
    "        # Simple test query\n",
    "        simple_query = \"machine learning applications\"\n",
    "        \n",
    "        # Run the complete workflow\n",
    "        print(f\"   - Running complete workflow for: {simple_query}\")\n",
    "        \n",
    "        initial_state = {\n",
    "            'original_query': simple_query,\n",
    "            'refined_query': '',\n",
    "            'search_results': [],\n",
    "            'processed_documents': [],\n",
    "            'context_chunks': [],\n",
    "            'final_answer': '',\n",
    "            'error': None,\n",
    "            'step': 'start'\n",
    "        }\n",
    "        \n",
    "        # This would run the full graph - for testing, we'll run abbreviated version\n",
    "        # result = research_agent.graph.invoke(initial_state)\n",
    "        \n",
    "        # Instead, let's test the research method if available\n",
    "        if hasattr(research_agent, 'research'):\n",
    "            result = await research_agent.research(simple_query)\n",
    "            print(f\"   - ‚úÖ Workflow completed successfully\")\n",
    "            print(f\"   - Final answer: {result.get('final_answer', 'No answer')[:200]}...\")\n",
    "        else:\n",
    "            print(\"   - Research method not available, skipping full workflow test\")\n",
    "    else:\n",
    "        print(\"   - Research agent not initialized, skipping workflow test\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Full workflow test failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Error Handling and Edge Cases Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing Error Handling and Edge Cases...\n",
      "   - Test 1: Empty query\n",
      "     Empty query result: (\"academic search query formulation\" OR \"scholarly literature search strategy\" OR \"research query optimization\") AND (\"information retrieval\" OR \"literature search methodology\")\n",
      "   - Test 2: Very long query\n",
      "     Long query handled: 162 chars\n",
      "   - Test 3: Invalid characters in query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-24 08:54:54,836 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu\n",
      "2025-07-24 08:54:54,837 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Invalid chars handled: (\"machine learning\" OR \"deep learning\" OR \"artific...\n",
      "   - Test 4: Vector store search with no documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-24 08:54:58,938 - vector_store - INFO - Initialized vector store with 0 documents\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 62.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Empty vector store search: 0 results\n",
      "   - Test 5: Document processing with invalid URL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-24 08:55:00,071 - document_processor - WARNING - Failed to download https://invalid-url-that-does-not-exist.com/paper.pdf: 404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Invalid URL handled: 0 chunks\n",
      "‚úÖ Error handling tests completed\n"
     ]
    }
   ],
   "source": [
    "# Test error handling and edge cases\n",
    "try:\n",
    "    print(\"üß™ Testing Error Handling and Edge Cases...\")\n",
    "    \n",
    "    # Test 1: Empty query\n",
    "    print(\"   - Test 1: Empty query\")\n",
    "    try:\n",
    "        empty_result = research_agent.query_refinement_tool.refine_query(\"\")\n",
    "        print(f\"     Empty query result: {empty_result}\")\n",
    "    except Exception as e:\n",
    "        print(f\"     Expected error for empty query: {e}\")\n",
    "    \n",
    "    # Test 2: Very long query\n",
    "    print(\"   - Test 2: Very long query\")\n",
    "    long_query = \"machine learning \" * 100  # Very long query\n",
    "    try:\n",
    "        long_result = research_agent.query_refinement_tool.refine_query(long_query)\n",
    "        print(f\"     Long query handled: {len(long_result)} chars\")\n",
    "    except Exception as e:\n",
    "        print(f\"     Error with long query: {e}\")\n",
    "    \n",
    "    # Test 3: Invalid characters in query\n",
    "    print(\"   - Test 3: Invalid characters in query\")\n",
    "    invalid_query = \"machine learning ü§ñ @#$%^&*()\"\n",
    "    try:\n",
    "        invalid_result = research_agent.query_refinement_tool.refine_query(invalid_query)\n",
    "        print(f\"     Invalid chars handled: {invalid_result[:50]}...\")\n",
    "    except Exception as e:\n",
    "        print(f\"     Error with invalid characters: {e}\")\n",
    "    \n",
    "    # Test 4: Vector store with no documents\n",
    "    print(\"   - Test 4: Vector store search with no documents\")\n",
    "    try:\n",
    "        empty_vector_store = VectorStore(\"./test_empty_db\", config.EMBEDDING_MODEL)\n",
    "        empty_search = empty_vector_store.similarity_search(\"test query\", k=5)\n",
    "        print(f\"     Empty vector store search: {len(empty_search)} results\")\n",
    "    except Exception as e:\n",
    "        print(f\"     Error with empty vector store: {e}\")\n",
    "    \n",
    "    # Test 5: Network error simulation (invalid URL)\n",
    "    print(\"   - Test 5: Document processing with invalid URL\")\n",
    "    try:\n",
    "        invalid_chunks = await doc_processor.process_paper(\n",
    "            \"https://invalid-url-that-does-not-exist.com/paper.pdf\",\n",
    "            \"Test Paper\"\n",
    "        )\n",
    "        print(f\"     Invalid URL handled: {len(invalid_chunks)} chunks\")\n",
    "    except Exception as e:\n",
    "        print(f\"     Error with invalid URL: {e}\")\n",
    "    \n",
    "    print(\"‚úÖ Error handling tests completed\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error handling test failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Performance and Resource Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing Performance and Resource Usage...\n",
      "   - Memory before tests: 776.25 MB\n",
      "   - Query refinement (3 queries): 21.08 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 58.19it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 45.45it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 55.57it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 45.68it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 52.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   - Vector search (5 searches): 0.14 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   - Memory after tests: 748.22 MB\n",
      "   - Memory difference: -28.03 MB\n",
      "   - Current CPU usage: 0.0%\n"
     ]
    }
   ],
   "source": [
    "# Test performance and resource usage\n",
    "import time\n",
    "import psutil\n",
    "import gc\n",
    "\n",
    "try:\n",
    "    print(\"üß™ Testing Performance and Resource Usage...\")\n",
    "    \n",
    "    # Memory usage before\n",
    "    process = psutil.Process()\n",
    "    memory_before = process.memory_info().rss / 1024 / 1024  # MB\n",
    "    print(f\"   - Memory before tests: {memory_before:.2f} MB\")\n",
    "    \n",
    "    # Test query refinement speed\n",
    "    start_time = time.time()\n",
    "    for i in range(3):\n",
    "        test_query = f\"machine learning test query {i}\"\n",
    "        refined = research_agent.query_refinement_tool.refine_query(test_query)\n",
    "    refinement_time = time.time() - start_time\n",
    "    print(f\"   - Query refinement (3 queries): {refinement_time:.2f} seconds\")\n",
    "    \n",
    "    # Test vector search speed\n",
    "    if 'vector_store' in locals():\n",
    "        start_time = time.time()\n",
    "        for i in range(5):\n",
    "            search_results = vector_store.similarity_search(f\"test query {i}\", k=3)\n",
    "        search_time = time.time() - start_time\n",
    "        print(f\"   - Vector search (5 searches): {search_time:.2f} seconds\")\n",
    "    \n",
    "    # Memory usage after\n",
    "    gc.collect()  # Force garbage collection\n",
    "    memory_after = process.memory_info().rss / 1024 / 1024  # MB\n",
    "    print(f\"   - Memory after tests: {memory_after:.2f} MB\")\n",
    "    print(f\"   - Memory difference: {memory_after - memory_before:.2f} MB\")\n",
    "    \n",
    "    # CPU usage\n",
    "    cpu_percent = process.cpu_percent()\n",
    "    print(f\"   - Current CPU usage: {cpu_percent:.1f}%\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Performance test failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Test Summary and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "                    TEST SUMMARY\n",
      "============================================================\n",
      "‚úÖ Configuration\n",
      "‚úÖ Gemini Client\n",
      "‚úÖ Scholar API\n",
      "‚úÖ Document Processor\n",
      "‚úÖ Vector Store\n",
      "‚úÖ Research Agent\n",
      "‚úÖ Search Results\n",
      "‚úÖ Document Chunks\n",
      "------------------------------------------------------------\n",
      "Overall Success Rate: 100.0% (8/8)\n",
      "üéâ System is functioning well!\n",
      "============================================================\n",
      "Test completed at: 2025-07-24 08:55:21.575358\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Generate test summary\n",
    "print(\"\" + \"=\" * 60)\n",
    "print(\"                    TEST SUMMARY\")\n",
    "print(\"\" + \"=\" * 60)\n",
    "\n",
    "test_results = []\n",
    "\n",
    "# Check what components were successfully tested\n",
    "components = [\n",
    "    ('Configuration', 'config' in locals()),\n",
    "    ('Gemini Client', 'gemini_client' in locals()),\n",
    "    ('Scholar API', 'scholar_api' in locals()),\n",
    "    ('Document Processor', 'doc_processor' in locals()),\n",
    "    ('Vector Store', 'vector_store' in locals()),\n",
    "    ('Research Agent', 'research_agent' in locals()),\n",
    "    ('Search Results', 'search_results' in locals() and len(search_results) > 0),\n",
    "    ('Document Chunks', 'document_chunks' in locals() and len(document_chunks) > 0),\n",
    "]\n",
    "\n",
    "for component, status in components:\n",
    "    status_icon = '‚úÖ' if status else '‚ùå'\n",
    "    print(f\"{status_icon} {component}\")\n",
    "\n",
    "print(\"\" + \"-\" * 60)\n",
    "\n",
    "# Overall system health\n",
    "passed_tests = sum(1 for _, status in components if status)\n",
    "total_tests = len(components)\n",
    "success_rate = (passed_tests / total_tests) * 100\n",
    "\n",
    "print(f\"Overall Success Rate: {success_rate:.1f}% ({passed_tests}/{total_tests})\")\n",
    "\n",
    "if success_rate >= 80:\n",
    "    print(\"üéâ System is functioning well!\")\n",
    "elif success_rate >= 60:\n",
    "    print(\"‚ö†Ô∏è  System has some issues that need attention.\")\n",
    "else:\n",
    "    print(\"üö® System has significant issues that need immediate attention.\")\n",
    "\n",
    "print(\"\" + \"=\" * 60)\n",
    "print(f\"Test completed at: {datetime.now()}\")\n",
    "print(\"\" + \"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
