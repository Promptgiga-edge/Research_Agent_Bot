# LangChain evaluation tools
langchain>=0.1.0
langchain-community>=0.0.20
langchain-experimental>=0.0.40

# Evaluation metrics and tools
evaluate>=0.4.0
datasets>=2.14.0
scikit-learn>=1.3.0
nltk>=3.8.1
rouge-score>=0.1.2
bleu>=0.1.0

# Embedding and similarity calculation
sentence-transformers>=2.2.0
faiss-cpu>=1.7.4
numpy>=1.24.0

# Network monitoring and mocking
responses>=0.23.0
httpx>=0.24.0
aioresponses>=0.7.4

# Additional utilities
pytest>=7.4.0
pytest-asyncio>=0.21.0
tqdm>=4.65.0
tabulate>=0.9.0

# Optional: For advanced evaluation metrics
bertscore>=0.3.13
sacrebleu>=2.3.0

